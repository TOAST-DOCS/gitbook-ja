## Compute > GPU Instance > 概要

GPUインスタンスはインスタンスにGPU(Graphics Processing Unit)が追加構成された仮想サーバーです。
科学的な発見からディープラーニングに至るまで、多様な分野で使用します。

GPU数1個または2個を選択してGPUを使用できます。

## 機能

* AIトレーニング
* AI推論
* 高性能コンピューティング

## 提供GPUの仕様

### NVIDIA V100

| NVIDIA V100 for NVLink | |
| ----------------------------- | :----------------------------------: |
| GPU  Architecture             |             NVIDIA Volta             |
| NVIDIA Tensor Cores           |                 640                  |
| NVIDIA CUDA Cores             |                 5120                 |
| DOUBLE-PRECISION Performance  |            7.8 teraFLOPS             |
| SINGLE-PRECISION  Performance |            15.7 teraFLOPS            |
| DEEP LEARNING Performance     |            125 teraFLOPS             |
| GPU Memory                    |              32GB HBM2               |
| Memory Bandwidth              |              900GB/sec               |
| Interconnect Bandwidth        |              300GB/sec               |
| System Interface              |            NVIDIA NVLink             |
| Max Power Comsumption         |                300 W                 |
| Compute APIs                  | CUDA, DirectCompute, OpenCL, OpenACC |


### NVIDIA T4

| NVIDIA  T4                               |                             |
| ---------------------------------------- | :---------------------------: |
| GPU Architecture                         | NVIDIA Turing               |
| NVIDIA Tensor Cores                      | 320                         |
| NVIDIA CUDA Cores                        | 2560                        |
| SINGLE-PRECISION  Performance            | 8.1 teraFLOPS               |
| Mixed-Precision  (FP16/FP32) Performance | 65 teraFLOPS                |
| INT8                                     | 130 teraFLOPS               |
| INT8                                     | 260 teraFLOPS               |
| GPU Memory                               | 16GB GDDR6                  |
| Memory Bandwidth                         | 300GB/sec                   |
| Interconnect Bandwidth                   | 32GB/sec                    |
| System Interface                         | x16 PCIe Gen3               |
| Max Power Comsumption                    | 70 W                        |
| Compute APIs                             | CUDA, NVIDIA TensorRT, ONNX |
