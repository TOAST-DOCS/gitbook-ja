## Compute > GPU Instance > 概要

GPUインスタンスはインスタンスにGPU(Graphics Processing Unit)が追加構成された仮想サーバーです。
科学的な発見からディープラーニングに至るまで、多様な分野で使用します。

GPU数1個または2個を選択してGPUを使用できます。

## 機能

* AIトレーニング
* AI推論
* 高性能コンピューティング

## 提供GPUの仕様

### NVLINK用NVIDIA TESLA V100

ディープラーニングのための究極の性能


| Tesla V100 for NVLink |  |
| --- | :---: |
| GPU Architecture | NVIDIA Volta |
| NVIDIA Tensor Cores | 640 |
| NVIDIA CUDA Cores | 5120 |
| Double-Precision Performance | 7.8 TFLOPS |
| Single-Precision Performance | 15.7 TFLOPS |
| Tensor Performance | 125 TFLOPS |
| GPU Memory | 32GB |
| Memory Bandwidth | 900GB/sec |
| ECC | Yes |
| Interconnect Bandwidth | 300GB/sec |
| System Interface | NVIDIA NVLink |
| Form Factor | SXM2 |
| Max Power Comsumption | 300 WATTS |
| Thermal Solution | Passive |
| Compute APIs | CUDA, DirectCompute, OpenCL ™ ,OpenACC |

